{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a4e8b53",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "The requirement is to use Neural Network models to predict the traffic demand given the historical data. In this case I am using a single **Logistic Regression Model** with **1 hidden layer**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142b097",
   "metadata": {},
   "source": [
    "First, we need to import all the libraries that we are going to need to complete the task. As a library, we will be using **pyTorch**. Also, for the data preprocessing we are using **numpy**, and for the visualization we will be using **pyplot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f5f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc834916",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572ead1",
   "metadata": {},
   "source": [
    "### Importing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99dfb814",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('train.npz')\n",
    "input_train = train['x'] #feature matrix\n",
    "label_train = train['y'] #label matrix\n",
    "location_train = train['locations'] #location matrix### Importing Valuation Data\n",
    "times_train = train['times'] #time matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb1eff",
   "metadata": {},
   "source": [
    "### Importing Valuation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172fec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.load('val.npz')\n",
    "input_val = val['x'] #feature matrix\n",
    "label_val = val['y'] #label matrix\n",
    "location_val = val['locations'] #location matrix\n",
    "times_val = val['times'] #time matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90637e",
   "metadata": {},
   "source": [
    "### Importing Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de8de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('test.npz')\n",
    "input_test = test['x'] #feature matrix\n",
    "location_test = test['locations'] #location matrix\n",
    "times_test = test['times'] #time matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8fd48",
   "metadata": {},
   "source": [
    "## Changing from NumPy Arrays into Tensors\n",
    "\n",
    "Here we are creating tensors from numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30de617",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = torch.from_numpy(input_train)\n",
    "labels_train = torch.from_numpy(label_train)\n",
    "\n",
    "inputs_val = torch.from_numpy(input_val)\n",
    "labels_val = torch.from_numpy(label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89bb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(inputs_train.float(), labels_train.float())\n",
    "val_ds = TensorDataset(inputs_val.float(), labels_val.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b601c38",
   "metadata": {},
   "source": [
    "### Creating DataLoader\n",
    "\n",
    "Now, we are creating dataloaders to load the data in batches (in our case we will be using batches of size 100).\n",
    "\n",
    "Since the training data is often sorted by the target labels, or at least it is not random, therefore, it is crucial for us to choose random data items for our batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f196f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_size = 8*49\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf00a45",
   "metadata": {},
   "source": [
    "### Shape\n",
    "\n",
    "Here, we can see that our items in the train_loader have the shape of (100(number of items in the batch), 8, 49). But for ou rfurther operations such as matrix multiplications, this shape is going to be invalid for us. Therefore, we need to reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1c10b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items.shape: torch.Size([100, 8, 49])\n",
      "inputs.shape: torch.Size([100, 392])\n"
     ]
    }
   ],
   "source": [
    "for items, labels in train_loader:\n",
    "    print('items.shape:', items.shape)\n",
    "    inputs = items.reshape(-1, 8*49)\n",
    "    print('inputs.shape:', inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace89c6e",
   "metadata": {},
   "source": [
    "The size of the hidden layer is going to be 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a46fb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = inputs.shape[-1]\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ef379",
   "metadata": {},
   "source": [
    "### Layer Creation\n",
    "\n",
    "Next, we will create a nn.Linear object that is going to be our hidden layer. The size is already defined to be 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "987bf05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = nn.Linear(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e465ac18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1_outputs.shape: torch.Size([100, 64])\n"
     ]
    }
   ],
   "source": [
    "L1_outputs = L1(inputs)\n",
    "print('layer1_outputs.shape:', L1_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a555255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_outputs_direct = inputs @ L1.weight.t() + L1.bias\n",
    "L1_outputs_direct.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32c231",
   "metadata": {},
   "source": [
    "The image of vectors of size 392 are now transformed into intermediate output vectors of lenght 64 after matrix multiplications and addition of bias.\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "L1_outputs and inputs have a linear relationship, where each element of L1_putputs is a weighted sum of elements of unputs. Therefore, layer 1 can only capture linear relationships. That is why we need some kind of function that would make the next relationship between L1 and L2 non-linear.\n",
    "\n",
    "This kind of function is called an activation function and there are typically 5 major functions which are Step, Tanh, ReLU, and leaky ReLU.\n",
    "\n",
    "In our case, we will be using ReLU (Rectified Linear Unit) as an activation function. What it does is it ignores the non-negative numbers, but the negative numbers are transformed to 0. This function is no derivativable, and therefore is a good choice for a function to get rid from linearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db08aada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min(L1_outputs): -56.520835876464844\n",
      "min(relu_outputs): 0.0\n"
     ]
    }
   ],
   "source": [
    "relu_outputs = F.relu(L1_outputs)\n",
    "print('min(L1_outputs):', torch.min(L1_outputs).item())\n",
    "print('min(relu_outputs):', torch.min(relu_outputs).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad702f",
   "metadata": {},
   "source": [
    "### Creation of Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1af9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2 = nn.Linear(hidden_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c53a4e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "L2_outputs = L2(relu_outputs)\n",
    "print(L2_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c1824",
   "metadata": {},
   "source": [
    "Now, layer 2 outputs contains a batch of vectors of size 1. Now, we can compute the loss using F.mse_loss (Mean Squared Loss) function and adjust the weights of L1 and L2 using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd69839f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(470.2571, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(L2_outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c646737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded version of layer2(F.relu(layer1(inputs)))\n",
    "outputs = (F.relu(inputs @ L1.weight.t() + L1.bias)) @ L2.weight.t() + L2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dbea19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as layer2(layer1(inputs))\n",
    "outputs2 = (inputs @ L1.weight.t() + L1.bias) @ L2.weight.t() + L2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b29e86c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single layer to replace the two linear layers\n",
    "combined_layer = nn.Linear(input_size, 1)\n",
    "\n",
    "combined_layer.weight.data = L2.weight @ L1.weight\n",
    "combined_layer.bias.data = L1.bias @ L2.weight.t() + L2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed5666b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as combined_layer(inputs)\n",
    "outputs3 = inputs @ combined_layer.weight.t() + combined_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d443b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
